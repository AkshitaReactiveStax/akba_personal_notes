
## **âœ… 301.**Â 

## **Which intrinsic lock is acquired by a synchronized method in Java?**

  

### **ğŸ”¹ Non-static synchronized method:**

  

Locks on the **current instance (this)**.

```
synchronized void print() {
    // Lock is on 'this'
}
```

### **ğŸ”¹ Static synchronized method:**

  

Locks on the **Class object**, i.e., MyClass.class.

```
synchronized static void log() {
    // Lock is on MyClass.class
}
```

> ğŸ§  This is called an **intrinsic lock** or **monitor lock**, managed implicitly by the JVM.

---

## **âœ… 302.**Â 

## **Can we mark a constructor as synchronized in Java?**

  

**No**, constructors **cannot be synchronized** because:

- The object is not fully constructed.
    
- The this reference is not available to other threads yet.
    
- Locking requires an object to lock on (this), which isnâ€™t fully available inside a constructor.
    

  

> ğŸ” JVM restriction: synchronized is disallowed on constructors syntactically.

  

**âœ… Instead:**

Use synchronized blocks inside constructors if needed:

```
public MyClass() {
    synchronized (MyClass.class) {
        // Safe shared resource setup
    }
}
```

---

## **âœ… 303.**Â 

## **Can we use primitive values for intrinsic locks?**

  

**No**, intrinsic locks (used in synchronized) can only be used on **Objects**, not **primitive types** (int, boolean, etc.).

```
int i = 0;
// synchronized(i) âŒ Invalid â€” causes compile-time error
```

> âœ… You can use boxed objects like Integer, but be **very cautious**:

> Integer values from -128 to 127 are **interned and shared**, which can lead to unintended lock sharing.

```
Integer i = 127;
synchronized (i) {
    // Dangerous - could lock shared cache object
}
```

---

## **âœ… 304.**Â 

## **Do we have re-entrant property in intrinsic locks?**

  

**Yes**, intrinsic locks in Java are **re-entrant**.

  

### **ğŸ” Reentrancy means:**

  

A thread that already holds the lock **can acquire it again** (even recursively), without getting blocked.

```
synchronized void outer() {
    inner(); // This is OK
}

synchronized void inner() {
    // Lock is re-acquired by same thread
}
```

> ğŸ”¥ Without reentrancy, this would cause a **self-deadlock**.

  

### **âœ… Both**Â 

### **synchronized**

### Â **and**Â 

### **ReentrantLock**

### Â **support reentrancy.**

---

## **âœ… 305.**Â 

## **What is an atomic operation?**

  

An **atomic operation** is one that is:

- **Indivisible**: Cannot be split by thread context switches.
    
- **Consistent**: Visible as a complete unit to other threads.
    
- **Uninterruptible**: Either fully happens or doesnâ€™t happen at all.
    

  

### **âœ… Examples:**

- int a = 10; (primitive assignment)
    
- volatile reads/writes for 32-bit types
    
- AtomicInteger.incrementAndGet()
    

---

## **âœ… 306.**Â 

## **Can we consider the statement i++ as an atomic operation in Java?**

  

**No**, i++ is **not atomic**. Itâ€™s a compound operation:

```
// i++ is broken into:
int temp = i;
temp = temp + 1;
i = temp;
```

This creates a **race condition** when multiple threads execute i++ concurrently.

  

### **ğŸ”¥ Interview Example:**

```
class Counter {
    int count = 0;
    public void increment() {
        count++; // âŒ Not thread-safe
    }
}
```

---

## **âœ… 307.**Â 

## **What are the Atomic operations in Java?**

  

Java provides the **java.util.concurrent.atomic** package for true atomic operations.

  

### **âœ… Key Classes:**

- AtomicInteger, AtomicLong, AtomicBoolean
    
- AtomicReference<T>
    
- LongAdder, DoubleAdder (for contention-heavy counters)
    

  

### **âœ… Atomic Methods:**

```
AtomicInteger counter = new AtomicInteger(0);
counter.incrementAndGet(); // Thread-safe ++
counter.getAndSet(10);     // Atomic set
counter.compareAndSet(5, 10); // CAS
```

### **ğŸ” Under the hood:**

  

Uses **Compare-And-Swap (CAS)** at the hardware level for **lock-free, thread-safe** behavior.

---

## **âœ… 308.**Â 

## **Can you check if the following code is thread-safe?**

```
class Counter {
    private int count = 0;

    public void increment() {
        count++;
    }

    public int getCount() {
        return count;
    }
}
```

### **âŒ Answer: This is**Â 

### **not thread-safe**

### **.**

- count++ is not atomic.
    
- No synchronization or visibility guarantees.
    
- getCount() may return stale data without volatile or synchronization.
    

  

### **âœ… Fixes:**

1. Use synchronized:
    

```
synchronized void increment() {
    count++;
}
```

2. Use AtomicInteger:
    

```
AtomicInteger count = new AtomicInteger();
public void increment() {
    count.incrementAndGet();
}
```

3. Use LongAdder for high-throughput counters.
    

---

## **âœ… 309.**Â 

## **What are the minimum requirements for a Deadlock situation in a program?**

  

According to **Coffmanâ€™s Conditions**, all 4 must be true:

|**Condition**|**Meaning**|
|---|---|
|Mutual Exclusion|At least one lock is held exclusively|
|Hold and Wait|Threads hold resources while waiting for others|
|No Preemption|Resources canâ€™t be forcefully taken away|
|Circular Wait|A cycle of threads, each waiting on anotherâ€™s resource|

> ğŸ”¥ Even if 3 out of 4 are present, deadlock **cannot** occur.

---

## **âœ… 310.**Â 

## **How can we prevent a Deadlock?**

  

### **ğŸ”‘ Strategies to prevent deadlock:**

---

### **ğŸ”¹ 1.**Â 

### **Lock ordering**

  

Acquire multiple locks in a **global fixed order**.

```
synchronized (lock1) {
    synchronized (lock2) {
        // Safe
    }
}
```

---

### **ğŸ”¹ 2.**Â 

### **Try-Lock with timeout**

  

Use ReentrantLock.tryLock(timeout) to avoid waiting forever.

```
if (lock1.tryLock(100, TimeUnit.MILLISECONDS)) {
    try {
        if (lock2.tryLock(100, TimeUnit.MILLISECONDS)) {
            // Do work
        }
    } finally {
        lock1.unlock();
        lock2.unlock();
    }
}
```

---

### **ğŸ”¹ 3.**Â 

### **Lock timeout and backoff algorithms**

  

Used in high-concurrency systems â€” abandon request after a timeout and retry later.

---

### **ğŸ”¹ 4.**Â 

### **Use high-level constructs**

  

Use:

- Executors
    
- ConcurrentHashMap
    
- BlockingQueue
    
    which **internally manage locks safely**.
    

---

### **ğŸ” JVM Tools for Detection:**

  

Use tools like:

- jstack
    
- VisualVM
    
- Java Mission Control
    
    to detect deadlocks at runtime.
    

---

## **ğŸ”š Final Interview-Ready Tips:**

|**Topic**|**Donâ€™t Miss**|
|---|---|
|Intrinsic Locks|Locked on this or Class, reentrant|
|Atomicity|Compound ops like i++ are **not** atomic|
|Lock Safety|Use Atomic* classes for high-concurrency counters|
|Deadlock Debugging|Use jstack, design lock ordering|
|Reentrancy|Prevents self-deadlock on recursive synchronized calls|

---




## **âœ… 311.**Â 

## **How can we detect a Deadlock situation?**

  

### **ğŸ”¹ Programmatically (Java 1.5+):**

```
ThreadMXBean bean = ManagementFactory.getThreadMXBean();
long[] ids = bean.findDeadlockedThreads();
if (ids != null) {
    ThreadInfo[] infos = bean.getThreadInfo(ids);
    for (ThreadInfo info : infos) {
        System.out.println("Deadlocked thread: " + info.getThreadName());
    }
}
```

### **ğŸ”¹ JVM Tools:**

- jstack <pid> â†’ detects â€œFound one Java-level deadlockâ€
    
- **VisualVM**, **Java Mission Control**, **jConsole** â†’ thread tab â†’ detects deadlocks visually
    

  

> ğŸ” JVM captures **both intrinsic and explicit lock** deadlocks (e.g., ReentrantLock).

---

## **âœ… 312.**Â 

## **What is a Livelock?**

  

A **livelock** occurs when two or more threads **continuously change state** in response to each other **but make no actual progress**.

  

### **ğŸ”¥ Example:**

```
Thread A: tries to avoid conflict â†’ yields  
Thread B: tries to avoid conflict â†’ yields  
Repeat forever, no one proceeds
```

> ğŸ§  Think of two people stepping side-to-side to avoid blocking each other in a hallway â€” forever.

  

### **ğŸ› ï¸ Solution:**

- Add backoff strategies
    
- Use retry limits
    
- Use atomic coordination
    

---

## **âœ… 313.**Â 

## **What is Thread starvation?**

  

**Starvation** occurs when a thread is **indefinitely blocked from accessing CPU or resources**, because other higher-priority threads are constantly favored.

  

### **ğŸ” Common Causes:**

- Using unfair locks
    
- Infinite loops with while(true) on high-priority threads
    
- Threads holding shared resource without yielding
    

---

## **âœ… 314.**Â 

## **How can a synchronized block cause Thread starvation in Java?**

  

If a thread holds a **synchronized lock** and:

- Performs long-running tasks
    
- Never yields control
    
- Prevents lower-priority threads from acquiring the lock
    

  

Then **other threads starve** for the monitor lock.

```
synchronized (sharedLock) {
    while (true) {
        // monopolizing the lock â€” others blocked
    }
}
```

> ğŸ”¥ To avoid: Keep synchronized blocks **minimal and efficient**.

---

## **âœ… 315.**Â 

## **What is a Race condition?**

  

A **race condition** occurs when:

- Two or more threads access **shared mutable state**
    
- The **correctness** of the outcome depends on **timing/interleaving**
    
- No synchronization or coordination is present
    

  

### **ğŸ”¥ Example:**

```
// Both threads increment count concurrently
count++; // Not atomic â†’ leads to lost updates
```

> ğŸ§  Race conditions can lead to **inconsistent state**, especially in **banking, inventory, or counters**.

---

## **âœ… 316.**Â 

## **What is a Fair lock in multi-threading?**

  

A **fair lock** ensures **first-come-first-serve (FIFO)** acquisition of the lock.

  

### **ğŸ”¹ Example:**

```
ReentrantLock fairLock = new ReentrantLock(true); // fairness = true
```

> ğŸ” With a fair lock, threads **acquire the lock in the order** they requested it.

  

### **âš ï¸ Downside:**

- More context switches
    
- Slower than unfair locks
    

---

## **âœ… 317.**Â 

## **Which two methods of Object class can be used to implement a Producer-Consumer scenario?**

  

### **âœ…**Â 

### **wait()**

### Â **and**Â 

### **notify()**

### Â **(or**Â 

### **notifyAll()**

### **)**

  

Used for **inter-thread communication**, especially in **bounded buffer scenarios**.

```
synchronized (buffer) {
    while (buffer.isEmpty()) {
        buffer.wait();
    }
    buffer.notify(); // Notify waiting producers or consumers
}
```

> ğŸ§  Use wait() inside a loop (not if) â€” to re-check condition after spurious wakeups.

---

## **âœ… 318.**Â 

## **How JVM determines which thread should wake up on notify()?**

  

**JVM does not guarantee any order** when selecting which thread to wake up.

- If multiple threads are waiting on the same monitor:
    
    - notify() wakes **one random** thread
        
    - notifyAll() wakes **all** waiting threads â†’ only one gets lock, rest re-enter waiting
        
    

  

> ğŸ” Scheduling and wake-up behavior are **OS- and JVM-dependent**.

  

### **âœ… Recommendation:**

  

Use notifyAll() unless youâ€™re sure **only one consumer** exists.

---

## **âœ… 319.**Â 

## **Check if the following code is thread-safe for retrieving an integer value from a Queue?**

```
Queue<Integer> queue = new LinkedList<>();

public Integer pollQueue() {
    return queue.poll();
}
```

### **âŒ**Â 

### **Not thread-safe**

- LinkedList is not thread-safe.
    
- Concurrent access can lead to:
    
    - Corruption
        
    - NullPointerException
        
    - Infinite loops
        
    

  

### **âœ… Fix:**

  

Use BlockingQueue or external synchronization.

```
BlockingQueue<Integer> queue = new LinkedBlockingQueue<>();
public Integer pollQueue() {
    return queue.poll();
}
```

Or:

```
synchronized (queue) {
    return queue.poll();
}
```

---

## **âœ… 320.**Â 

## **How can we check if a thread has a monitor lock on a given object?**

  

### **ğŸ” JVM provides**Â 

### **Thread.holdsLock(Object obj)**

### **:**

```
if (Thread.holdsLock(myObject)) {
    System.out.println("Current thread holds lock on myObject");
}
```

### **ğŸ”¥ Use case:**

- Useful in complex lock management
    
- Helps debug **synchronization issues**
    
- Validate lock preconditions
    

---

## **ğŸ§  Deep Insights Most Candidates Miss**

|**Concept**|**Insight**|
|---|---|
|notify() behavior|Wakes a **random** thread â€” not FIFO|
|Fair vs unfair locks|Fair locks â‰  always better â€” adds latency due to context switching|
|wait() in a loop|Required due to **spurious wakeups**|
|Livelock vs Deadlock|Livelock = active but stuck, Deadlock = blocked and stuck|
|Thread.holdsLock()|Often missed in debugging scenarios|
|BlockingQueue vs Queue|Thread-safe alternative that handles producer-consumer cases gracefully|

---



## **âœ… 321.**Â 

## **What is the use of yield() method in Thread class?**

  

The Thread.yield() method is a **hint to the scheduler** that the current thread is willing to **pause its execution**, allowing other threads of **equal or higher priority** to execute.

```
Thread.yield(); // Suggests the scheduler to reschedule
```

### **ğŸ” Internals:**

- It **does NOT release locks**.
    
- It may or may not cause actual yielding â€” depends on OS and JVM.
    
- Itâ€™s often used in spin-wait loops or low-priority background threads.
    

  

> âš ï¸ Do not rely on yield() for synchronization or fairness. Itâ€™s non-deterministic.

---

## **âœ… 322.**Â 

## **What is an important point to consider while passing an object from one thread to another thread?**

  

**Thread safety and visibility.**

  

When passing objects between threads:

  

### **âœ… Consider:**

1. **Mutability**: Is the object being shared mutable?
    
2. **Thread safety**: Are all accesses to shared state properly synchronized?
    
3. **Happens-before relationship**: Ensure visibility using:
    
    - Volatile
        
    - Synchronization
        
    - Atomic references
        
    - Final fields in constructors
        
    

  

> ğŸ§  If a thread modifies an object and another thread reads it, there must be a **happens-before** edge to guarantee visibility.

---

## **âœ… 323.**Â 

## **What are the rules for creating Immutable Objects?**

  

### **ğŸ”’ To make a class truly**Â 

### **immutable**

### **:**

1. Declare the class final
    
2. Make all fields private final
    
3. Do not provide setters
    
4. Initialize fields via constructor
    
5. Do **deep copies** of mutable objects (e.g., Date, collections)
    
6. Avoid exposing internal state via getters
    

```
public final class Person {
    private final String name;
    private final List<String> hobbies;

    public Person(String name, List<String> hobbies) {
        this.name = name;
        this.hobbies = List.copyOf(hobbies); // defensive copy
    }

    public List<String> getHobbies() {
        return List.copyOf(hobbies); // prevents mutation
    }
}
```

> ğŸ’¡ Immutable objects are inherently **thread-safe**.

---

## **âœ… 324.**Â 

## **What is the use of ThreadLocal class?**

  

ThreadLocal<T> provides **thread-local variables** â€” each thread accessing the variable has its own **independent copy**, isolated from others.

```
ThreadLocal<Integer> threadLocalId = ThreadLocal.withInitial(() -> 0);
```

### **ğŸ” Internals:**

- Each thread has a **ThreadLocalMap**
    
- ThreadLocal avoids synchronization for per-thread state
    
- Common in:
    
    - Request tracing
        
    - User sessions
        
    - DB connections per thread
        
    

  

> âš ï¸ Memory leak risk in **thread pools** if remove() is not called.

---

## **âœ… 325.**Â 

## **What are the scenarios suitable for using ThreadLocal class?**

  

### **âœ… Ideal for:**

1. **Per-thread state caching**
    
2. **Avoiding passing context explicitly**
    
3. **Thread-safe object reuse**:
    
    - SimpleDateFormat
        
    - JDBC connections
        
    - Security context
        
    - Request-scoped beans in web apps
        
    

```
private static final ThreadLocal<SimpleDateFormat> formatter =
    ThreadLocal.withInitial(() -> new SimpleDateFormat("yyyy-MM-dd"));
```

> âš ï¸ Clean up using remove() after use in thread pools to prevent leaks.

---

## **âœ… 326.**Â 

## **How will you improve the performance of an application by multithreading?**

  

### **âœ… Strategies:**

1. **Decompose into independent tasks**
    
    - I/O operations
        
    - CPU-heavy computations
        
    
2. **Parallelize using:**
    
    - ExecutorService
        
    - ForkJoinPool
        
    - CompletableFuture
        
    
3. **Use asynchronous models** where possible:
    
    - Non-blocking I/O
        
    - Reactive programming
        
    
4. **Minimize lock contention**
    
    - Use fine-grained locking or lock-free data structures
        
    
5. **Leverage multi-core CPUs**
    

  

> ğŸ§  Remember: More threads â‰  better performance unless task granularity is well-managed.

---

## **âœ… 327.**Â 

## **What is scalability in a software program?**

  

Scalability is the systemâ€™s ability to **handle increased load** (users, requests, data, etc.) by **increasing resources** without degrading performance.

  

### **ğŸ” Types:**

- **Vertical scaling**: Adding more power (CPU/RAM) to a single machine
    
- **Horizontal scaling**: Adding more machines (distributed systems)
    

  

### **ğŸ“ˆ For multithreading:**

  

A system is scalable if adding threads or cores **leads to higher throughput** â€” up to a point.

---

## **âœ… 328.**Â 

## **How will you calculate the maximum speed up of an application by using multiple processors?**

  

### **âœ… Use**Â 

### **Amdahlâ€™s Law**

### **:**

  

\text{Speedup} = \frac{1}{(1 - P) + \frac{P}{N}}

  

Where:

- P = Proportion of the program that can be parallelized
    
- N = Number of processors
    

  

### **ğŸ” Implication:**

- Even with infinite processors, speedup is limited by the **serial portion** of the code.
    

  

> ğŸ§  Best use: Identify **bottlenecks** that cannot be parallelized.

---

## **âœ… 329.**Â 

## **What is Lock contention in multithreading?**

  

**Lock contention** occurs when multiple threads try to acquire the same lock **simultaneously**, leading to **blocked threads**, **reduced throughput**, and **performance degradation**.

  

### **ğŸ” Symptoms:**

- High thread CPU usage with low work done
    
- Threads stuck in BLOCKED state
    
- Long GC pauses (due to held locks)
    

  

### **Tools:**

- VisualVM
    
- jstack showing blocked threads
    
- Java Flight Recorder (JFR)
    

---

## **âœ… 330.**Â 

## **What are the techniques to reduce Lock contention?**

  

### **âœ… Top Strategies:**

|**Technique**|**Purpose**|
|---|---|
|**Use finer-grained locks**|Reduce scope of locking|
|**Use ReentrantLock.tryLock()**|Avoid waiting forever|
|**Use concurrent collections**|ConcurrentHashMap, BlockingQueue|
|**Use immutable data**|Avoid shared state|
|**Reduce synchronization scope**|Sync only where needed|
|**Read-write locks**|ReentrantReadWriteLock for read-heavy workloads|
|**Lock striping**|Multiple locks for different subsets of data|
|**Use CAS**|Lock-free updates via Atomic* classes|

> ğŸ§  Lock contention scales **non-linearly** â€” reducing it early saves more than fixing it later.

---

## **ğŸ”š Final Pro Interview Insights**

|**Topic**|**Interview Edge Youâ€™ll Have**|
|---|---|
|ThreadLocal pitfalls|Mention remove() in thread pools to show depth|
|Scalability|Refer to **Amdahlâ€™s Law** with real examples|
|Lock contention|Cite use of **striping, CAS, concurrent utils**|
|yield()|Clarify itâ€™s a **scheduler hint**, not a synchronization tool|
|Immutable patterns|Mention **deep copy**, not just final and no setters|

---



## **âœ… 331.**Â 

## **What technique can be used in the following code to reduce Lock contention?**

```
public class Counter {
    private int[] buckets = new int[10];

    public synchronized void increment(int index) {
        buckets[index]++;
    }
}
```

### **ğŸ”¥ Problem:**

- Entire method is synchronized â†’ **global lock** across all buckets
    
- Even independent buckets[index] calls must wait
    

  

### **âœ… Solution:**Â 

### **Use Lock Striping**

  

Replace single global lock with **per-bucket lock**.

```
private final Object[] locks = new Object[10];

public Counter() {
    for (int i = 0; i < 10; i++) locks[i] = new Object();
}

public void increment(int index) {
    synchronized (locks[index]) {
        buckets[index]++;
    }
}
```

> ğŸ§  This reduces contention by **allowing multiple threads to work on different buckets simultaneously**.

---

## **âœ… 332.**Â 

## **What is Lock Splitting technique?**

  

**Lock Splitting** divides a single coarse-grained lock into **multiple independent locks** that guard different internal states of an object.

  

### **ğŸ” Used When:**

- Object has multiple independent fields
    
- Threads frequently access disjoint parts
    

  

### **ğŸ§  Example:**

  

A Hashtable with one lock suffers from contention. ConcurrentHashMap uses lock splitting:

- Each bucket or segment has its own lock
    

  

### **Benefits:**

- Increased throughput
    
- Fine-grained concurrency
    

  

> ğŸ”¥ JVM itself uses lock splitting in class metadata, hash tables, and memory managers.

---

## **âœ… 333.**Â 

## **Which technique is used in ReadWriteLock class for reducing lock contention?**

  

**Reader-writer decomposition** (also known as **read-write lock** pattern)

  

### **âœ… Mechanism:**

- Multiple readers can access the resource **concurrently**
    
- Only one writer is allowed at a time (exclusive lock)
    

```
ReadWriteLock lock = new ReentrantReadWriteLock();
lock.readLock().lock();
// multiple readers allowed
```

### **ğŸ§  Ideal for:**

- **Read-heavy** systems like caches, config managers, file scanners
    
- Reduces write starvation via fair locking policies
    

---

## **âœ… 334.**Â 

## **What is Lock Striping?**

  

Lock Striping = Using **an array of smaller locks** to guard a larger shared data structure.

```
Object[] locks = new Object[16]; // stripes
int hash = key.hashCode() % locks.length;
synchronized(locks[hash]) {
    // operate on partitioned resource
}
```

### **âœ… Real-World Use:**

- ConcurrentHashMap (Java 7) uses lock striping per segment
    
- Allows higher concurrency with reduced contention
    

  

> ğŸ” Modern ConcurrentHashMap (Java 8+) uses **CAS + synchronized fallback**, not lock striping.

---

## **âœ… 335.**Â 

## **What is a CAS operation?**

  

**CAS = Compare-And-Swap**

  

A **lock-free**, atomic operation supported at the **CPU level** that does:

```
if (current == expected) {
    current = newValue;
    return true;
}
```

### **Used in:**

- Atomic classes (AtomicInteger, AtomicReference)
    
- Lock-free queues/stacks
    
- Synchronizers like StampedLock
    

  

### **CPU Instruction:**

- CMPXCHG on x86
    

  

> ğŸ” CAS is the foundation of **non-blocking concurrency** in Java and avoids kernel-level locking.

---

## **âœ… 336.**Â 

## **Which Java classes use CAS operation?**

  

### **âœ… Key CAS-enabled classes:**

- AtomicInteger, AtomicLong, AtomicReference
    
- ConcurrentLinkedQueue
    
- ConcurrentHashMap (Java 8+)
    
- LongAdder, Striped64
    
- StampedLock
    

  

### **ğŸ” Internals:**

- Backed by **Unsafe.compareAndSwap*** methods
    
- Uses **looping retry** on CAS failure (spin-based)
    
- Avoids context switching and reduces lock contention
    

---

## **âœ… 337.**Â 

## **Is it always possible to improve performance by object pooling in a multithreading application?**

  

**No** â€” object pooling is **not a guaranteed performance win** in multithreading. It can actually **degrade performance** due to:

  

### **âŒ Downsides:**

- **Contention on the pool itself** (locks/synchronization)
    
- **Wasted memory** (over-pooling)
    
- **GC pressure** due to retained references
    
- **Increased complexity** and bugs
    

  

### **âœ… Only use pooling for:**

- **Expensive-to-create** objects (e.g., DB connections, threads)
    
- **Recyclable resources** (e.g., buffers, parsers)
    

  

> ğŸ§  For cheap, short-lived, non-GC-heavy objects, pooling is **counterproductive** in modern JVMs.

---

## **âœ… 338.**Â 

## **How can techniques used for performance improvement in a single-threaded application degrade the performance in a multithreading application?**

  

### **ğŸ”¥ Examples:**

|**Single-thread Optim**|**Multithread Penalty**|
|---|---|
|Caching in static field|Shared state â†’ synchronization overhead|
|Using non-thread-safe collections|Race conditions, data corruption|
|Aggressive object reuse|False sharing, cache line contention|
|Manual memory reuse|Increased GC retention â†’ memory leaks|
|Tight loops without yielding|CPU monopolization in thread pools|

> ğŸ§  Optimizations must shift from **â€œspeedâ€ to â€œconcurrency awarenessâ€** in multi-threaded code.

---

## **âœ… 339.**Â 

## **What is the relation between Executor and ExecutorService interface?**

- Executor is the **base interface** with a single method:
    

```
void execute(Runnable command);
```

- ExecutorService extends Executor and adds:
    
    - Lifecycle management (shutdown(), awaitTermination())
        
    - Task submission (submit())
        
    - invokeAll(), invokeAny()
        
    - Future-based handling
        
    

  

### **âœ… Example:**

```
ExecutorService pool = Executors.newFixedThreadPool(10);
pool.submit(() -> System.out.println("Task"));
pool.shutdown();
```

> ğŸ§  Always prefer ExecutorService or even ScheduledExecutorService for real-world apps â€” they provide **better control and safety**.

---

## **âœ… 340.**Â 

## **What will happen on calling submit() method of an ExecutorService instance whose queue is already full?**

  

It depends on the **BlockingQueue implementation** and **RejectedExecutionHandler** strategy.

  

### **ğŸ” Scenario:**

```
ThreadPoolExecutor executor = new ThreadPoolExecutor(
    2, 4,
    60L, TimeUnit.SECONDS,
    new ArrayBlockingQueue<>(2),
    new ThreadPoolExecutor.AbortPolicy() // default
);
```

If the pool size is maxed out and the queue is full:

```
executor.submit(task); // âŒ throws RejectedExecutionException
```

### **âœ… Other handlers:**

|**Policy**|**Behavior**|
|---|---|
|AbortPolicy (default)|Throws exception|
|CallerRunsPolicy|Runs task in calling thread|
|DiscardPolicy|Silently drops the task|
|DiscardOldestPolicy|Drops oldest task in queue, enqueues new|

> ğŸ§  Use metrics + monitoring to detect saturation â€” not just exception handling.

---

## **ğŸ”š Interview-Winning Tips Summary**

|**Insightful Nugget**|**Why Interviewers Love It**|
|---|---|
|Lock Striping vs Lock Splitting|Demonstrates system-level thinking|
|submit() behavior on full queue|Real-world handling of thread pool saturation|
|CAS Internals|Shows knowledge of lock-free and hardware-level ops|
|Amdahlâ€™s Law vs Object Pooling|Shows you think in tradeoffs, not cargo cults|
|ThreadLocal cleanup|Prevents leaks in real prod systems|

---




## **âœ… 341.**Â 

## **What is a ScheduledExecutorService?**

  

ScheduledExecutorService is an interface in java.util.concurrent that allows you to:

- **Schedule tasks** to run after a delay
    
- **Run tasks periodically** at a fixed rate or fixed delay
    

```
ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(2);
scheduler.schedule(() -> System.out.println("Run after delay"), 5, TimeUnit.SECONDS);
scheduler.scheduleAtFixedRate(() -> doWork(), 0, 10, TimeUnit.SECONDS);
```

### **ğŸ” Types of Scheduling:**

|**Method**|**Description**|
|---|---|
|schedule()|One-time delay|
|scheduleAtFixedRate()|Fixed interval between **task starts**|
|scheduleWithFixedDelay()|Fixed interval between **task ends** and next start|

### **ğŸ”¬ Internals:**

- Backed by a **DelayedWorkQueue**
    
- Uses **timer wheels** internally for scheduling precision
    
- Exception in scheduled task will cancel that task but not the scheduler
    

  

> ğŸ§  Often preferred over Timer because itâ€™s thread-safe, handles exceptions better, and allows concurrent task execution.

---

## **âœ… 342.**Â 

## **How will you create a Thread pool in Java?**

  

Java provides the ExecutorService interface to manage thread pools:

  

### **âœ… Common ways:**

```
// Fixed number of threads
ExecutorService fixedPool = Executors.newFixedThreadPool(4);

// Cached pool (unbounded)
ExecutorService cachedPool = Executors.newCachedThreadPool();

// Single-threaded executor
ExecutorService single = Executors.newSingleThreadExecutor();

// Custom thread pool (full control)
ThreadPoolExecutor pool = new ThreadPoolExecutor(
    4, 8, 60L, TimeUnit.SECONDS,
    new ArrayBlockingQueue<>(100),
    Executors.defaultThreadFactory(),
    new ThreadPoolExecutor.AbortPolicy()
);
```

### **ğŸ” Thread Pool Parameters:**

- **corePoolSize**
    
- **maximumPoolSize**
    
- **keepAliveTime**
    
- **BlockingQueue**
    
- **ThreadFactory**
    
- **RejectedExecutionHandler**
    

  

> ğŸ§  Always shut down a pool gracefully with shutdown() or shutdownNow().

---

## **âœ… 343.**Â 

## **What is the main difference between Runnable and Callable interface?**

|**Feature**|Runnable|Callable<V>|
|---|---|---|
|Return value|âŒ No return|âœ… Returns result of type V|
|Exceptions|âŒ Canâ€™t throw checked|âœ… Can throw checked exceptions|
|Integration|Thread, ExecutorService|Only ExecutorService.submit()|
|Use cases|Fire-and-forget tasks|Compute tasks with result|

```
Callable<Integer> task = () -> 2 + 3;
Future<Integer> result = executor.submit(task);
```

> ğŸ”¥ Interview trap: You canâ€™t use Thread constructor with Callable.

---

## **âœ… 344.**Â 

## **What are the uses of Future interface in Java?**

  

Future<V> represents the **result of an asynchronous computation**, returned by ExecutorService.submit().

  

### **ğŸ” Key methods:**

|**Method**|**Purpose**|
|---|---|
|get()|Block until result is ready|
|get(timeout)|Wait with timeout|
|cancel()|Attempts to stop task|
|isDone()|Returns true if task is complete|
|isCancelled()|Returns true if task was cancelled|

```
Future<Integer> future = executor.submit(() -> expensiveCalculation());
Integer result = future.get(); // blocks
```

### **âš ï¸ Caveats:**

- get() is **blocking** â€” avoid calling it on main/UI thread
    
- Canceled tasks may not stop unless task checks Thread.interrupted()
    

  

> ğŸ§  FutureTask is the implementation that wraps Callable and manages result internally.

---

## **âœ… 345.**Â 

## **What is the difference in concurrency in HashMap and Hashtable?**

|**Feature**|HashMap|Hashtable|
|---|---|---|
|Thread-safety|âŒ Not thread-safe|âœ… Fully synchronized|
|Performance|Faster in single-threaded|Slower due to locking|
|Null keys/values|âœ… Allows 1 null key, many null values|âŒ No null key or value allowed|
|Synchronization|You must handle externally|Built-in synchronization|

### **ğŸ”¥ Internals:**

- Hashtable synchronizes **every method**, even read operations.
    
- HashMap requires **ConcurrentHashMap** or Collections.synchronizedMap() for thread safety.
    

  

> ğŸ§  Modern Java discourages Hashtable. Prefer **ConcurrentHashMap** for concurrent access.

---

## **âœ… 346.**Â 

## **How will you create synchronized instance of List or Map Collection?**

  

Java provides **wrapper methods** in Collections class:

```
List<String> syncList = Collections.synchronizedList(new ArrayList<>());
Map<String, String> syncMap = Collections.synchronizedMap(new HashMap<>());
```

### **âš ï¸ Important:**

- These wrappers synchronize **each method**.
    
- **Iteration must be manually synchronized** to avoid ConcurrentModificationException.
    

```
synchronized (syncList) {
    for (String item : syncList) {
        // safe iteration
    }
}
```

> ğŸ§  These are **coarse-grained** locks. For better scalability, use ConcurrentHashMap, CopyOnWriteArrayList, etc.

---

## **ğŸ” BONUS: Interview Insights Most Candidates Miss**

|**Detail**|**Why It Matters**|
|---|---|
|ScheduledExecutorService vs Timer|Timer uses a single thread; ScheduledExecutor scales better|
|Future.get() caveats|Blocking call â†’ can hang if not used with timeout|
|ThreadPoolExecutor rejection strategies|Shows real-world readiness (e.g., CallerRunsPolicy)|
|Callable for checked exceptions|Runnable canâ€™t propagate checked exceptions cleanly|
|Manual sync on synchronizedList.iterator()|Missed by 90% of candidates â€” leads to ConcurrentModificationException|

---




## **âœ… 347.**Â 

## **What is a Semaphore in Java?**

  

A Semaphore is a **counting-based concurrency control mechanism** from java.util.concurrent. It limits the **number of threads** that can access a resource simultaneously.

```
Semaphore semaphore = new Semaphore(3); // 3 permits
semaphore.acquire(); // blocks if no permits available
try {
    // access shared resource
} finally {
    semaphore.release(); // return permit
}
```

### **ğŸ” Types:**

- **Fair semaphore**: FIFO granting of permits.
    
- **Unfair semaphore**: May allow barging (default, better performance).
    

  

### **ğŸ§  Real-World Uses:**

- Connection pools
    
- Rate limiting
    
- Limiting concurrent API usage
    
- Bounded processing (e.g. printing 3 documents at a time)
    

---

## **âœ… 348.**Â 

## **What is a CountDownLatch in Java?**

  

CountDownLatch allows one or more threads to **wait until a set of operations are completed** by other threads.

```
CountDownLatch latch = new CountDownLatch(3);

new Thread(() -> {
    // Task done
    latch.countDown();
}).start();

latch.await(); // blocks until count reaches 0
```

### **ğŸ” Key Properties:**

- **One-time use**: Cannot be reset
    
- Thread-safe
    
- Does not support cyclic use like CyclicBarrier
    

---

## **âœ… 349.**Â 

## **What is the difference between CountDownLatch and CyclicBarrier?**

|**Feature**|CountDownLatch|CyclicBarrier|
|---|---|---|
|Resettable|âŒ No|âœ… Yes (can be reused)|
|Waits for|One or more threads|A fixed number of threads|
|Use case|Master-worker, task dependency|Barrier-based coordination|
|Runnable hook|âŒ No callback support|âœ… Can run a task at barrier point|

### **ğŸ§  Interview Tip:**

  

Use CountDownLatch when tasks are **independent** but one thread **must wait**, and CyclicBarrier when threads need to **meet at a checkpoint**.

---

## **âœ… 350.**Â 

## **What are the scenarios suitable for using Fork/Join framework?**

  

### **âœ… Best for:**

- Divide-and-conquer parallelism
    
- CPU-bound recursive tasks
    
- Tree-based processing (XML, directory traversal)
    
- Mergesort, quicksort, map-reduce-style logic
    

```
ForkJoinPool pool = ForkJoinPool.commonPool();
pool.invoke(new MyRecursiveTask());
```

### **ğŸ” Internals:**

- **Work-stealing**: Idle threads â€œstealâ€ subtasks from busy ones
    
- Uses **Deque** internally for load balancing
    
- Introduced in Java 7
    

  

> âš ï¸ Inefficient for I/O-bound tasks. Use ExecutorService instead.

---

## **âœ… 351.**Â 

## **What is the difference between RecursiveTask and RecursiveAction?**

|**Feature**|RecursiveTask<V>|RecursiveAction|
|---|---|---|
|Return type|âœ… Has return value|âŒ Void return|
|Typical usage|Sum, result computation|File traversal, action-only tasks|

### **âœ… Example:**

```
class SumTask extends RecursiveTask<Integer> {
    protected Integer compute() { return 1 + 2; }
}

class PrintTask extends RecursiveAction {
    protected void compute() { System.out.println("Hello"); }
}
```

> ğŸ§  RecursiveTask = â€œwhatâ€, RecursiveAction = â€œdoâ€.

---

## **âœ… 352.**Â 

## **In Java 8, can we process stream operations with a Thread pool?**

  

### **âœ… YES â€” but**Â 

### **not with parallelStream() directly**

### **.**

  

To use a **custom thread pool**, you must submit the **entire stream processing** to a pool:

```
ExecutorService executor = Executors.newFixedThreadPool(4);
List<Integer> result = executor.submit(() ->
    list.stream().map(...).collect(Collectors.toList())
).get();
```

> âš ï¸ parallelStream() uses **common ForkJoinPool**, which is **shared globally**.

  

### **ğŸ§  Why important?**

  

Using parallelStream() in web servers like Tomcat can cause **ForkJoinPool starvation**, degrading request processing.

---

## **âœ… 353.**Â 

## **What are the scenarios to use parallel stream in Java 8?**

  

### **âœ… Best for:**

- CPU-bound operations
    
- Large datasets
    
- Independent, stateless operations
    

  

### **âŒ Avoid when:**

- Side effects exist (I/O, shared state)
    
- Order must be preserved
    
- Task is I/O-bound or blocking
    
- Under small dataset (<1000 elements)
    

  

> ğŸ§  Always measure performance â€” parallelStream() may be slower due to thread management overhead.

---

## **âœ… 354.**Â 

## **How Stack and Heap work in Java multi-threading environment?**

|**Memory Area**|**Behavior in Multithreading**|
|---|---|
|**Heap**|Shared among all threads. Objects live here.|
|**Stack**|Each thread has its **own stack**. Stores method frames, local vars, PC register.|

### **ğŸ” Key Concepts:**

- Thread-local variables are stored in **Thread Stack**
    
- All objects created via new are in Heap, but references can be stack-allocated
    
- ThreadLocal uses internal map stored in the **Thread object**
    

  

> ğŸ§  Stack memory is safe by default. Heap access must be **synchronized or guarded**.

---

## **âœ… 355.**Â 

## **How can we take Thread dump in Java?**

  

### **ğŸ”¹ Ways to take thread dump:**

|**Method**|**Description**|
|---|---|
|jstack <pid>|CLI tool for live JVM thread dump|
|kill -3 <pid> (Unix)|Sends SIGQUIT, prints to stderr|
|**VisualVM / JMC / jConsole**|GUI-based thread dump|
|Programmatic|Thread.getAllStackTraces()|

> ğŸ§  Use thread dumps to identify deadlocks, bottlenecks, blocked threads.

---

## **âœ… 356.**Â 

## **Which parameter can be used to control stack size of a thread in Java?**

  

Use Thread constructor:

```
Thread t = new Thread(null, runnable, "worker", 1 * 1024 * 1024);
```

Or, for java command-line:

```
java -Xss512k MyApp
```

### **ğŸ§  Why control it?**

- Large recursion â†’ needs large stack
    
- Small stack â†’ lower memory footprint for thousands of threads
    

  

> âš ï¸ Too small = StackOverflowError. Tune based on method call depth.

---

## **âœ… 357.**Â 

## **There are two threads T1 and T2. How will you ensure that these threads run in sequence T1, then T2 in Java?**

  

### **âœ… Option 1:**Â 

### **join()**

```
Thread t1 = new Thread(() -> System.out.println("T1"));
Thread t2 = new Thread(() -> {
    try { t1.join(); } catch (InterruptedException e) {}
    System.out.println("T2");
});

t1.start();
t2.start();
```

### **âœ… Option 2:**Â 

### **CountDownLatch**

```
CountDownLatch latch = new CountDownLatch(1);

Thread t1 = new Thread(() -> {
    System.out.println("T1");
    latch.countDown();
});
Thread t2 = new Thread(() -> {
    try { latch.await(); } catch (InterruptedException e) {}
    System.out.println("T2");
});
```

### **âœ… Option 3:**Â 

### **Executors**

  

Use a single-threaded executor to guarantee order.

---

## **ğŸ§  Hidden Interview Gems Most Miss**

|**Concept**|**Insight**|
|---|---|
|ForkJoinPool common pitfalls|Donâ€™t use parallelStream in servlet containers|
|-Xss tuning|Crucial for high-scale apps with many threads|
|Work stealing|ForkJoinPool uses **Deque + LIFO/FIFO + CAS**|
|Thread.getAllStackTraces()|Can be used in diagnostics or profilers|
|RecursiveAction vs Task|Return value = use Task, else use Action|

---

